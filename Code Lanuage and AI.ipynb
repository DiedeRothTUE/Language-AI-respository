{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "112c1bad-ca00-46f9-919e-be71ce0d749f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diede\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\diede\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf4e0d98-86cb-4907-a4b2-a1f4cab9841e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('political_leaning.csv')\n",
    "#function that does for a given string do the pre processing (lowercase,puncatation, tokenizing and stopwords\n",
    "def prepro(text): \n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    processed_text = ' '.join(filtered_tokens)\n",
    "    return processed_text\n",
    "#a function that uses Textblob to perform basic sentiment analysis, note that we converge sentiment here to a qualtative statement\n",
    "#this was however not very smart, as our SVM needs a qaulitative stament, however as it took a long time to run this model, we converge this back in a later stage. \n",
    "def sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment_polarity = blob.sentiment.polarity\n",
    "    sentiment_subjectivity = blob.sentiment.subjectivity\n",
    "    if sentiment_subjectivity > 0.5:\n",
    "        sentiment_subjectivity = 'SUBJECTIVE'\n",
    "    else:\n",
    "        sentiment_subjectivity = 'NEUTRAL'\n",
    "    if sentiment_polarity > 0.4:\n",
    "        sentiment_polarity = 'POS'\n",
    "    elif sentiment_polarity < -0.4:\n",
    "        sentiment_polarity = 'NEG'\n",
    "    else: \n",
    "        sentiment_polarity = 'NEUTRAL'\n",
    "    return sentiment_polarity, sentiment_subjectivity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bab33423-c6ca-4c77-b7ac-7f5b0a92c098",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUBJECTIVE'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test if sentiment worked\n",
    "sentiment(data['post'][1])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1201557-9a26-4f9f-ad33-bce2e1690605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#adding new columns \n",
    "data['processed_text'] = ''\n",
    "data['sentiment_polarity'] = ''\n",
    "data['sentiment_subjectivity'] =''\n",
    "#applying the functions\n",
    "for x in range(0,len(data)): \n",
    "    data['processed_text'][x] = prepro(data['post'][x])\n",
    "    data['sentiment_polarity'][x] = sentiment(data['post'][x])[0]\n",
    "    data['sentiment_subjectivity'][x] = sentiment(data['post'][x])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79f18c68-529a-4f6a-9627-4f5c7b45e372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#saving the data to csv (so we don't need to run the code again)\n",
    "data.to_csv('processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdd8d20e-2d39-440e-86fb-03cc5aeb10df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reading the data in and the for  deleting 80% percent (for perfomance issues)\n",
    "data = pd.read_csv('processed.csv')\n",
    "#data = data.sample(frac=0.2, random_state=42) \n",
    "#installing the encoder for sentiment\n",
    "encoder = OneHotEncoder()\n",
    "X_sentiment = encoder.fit_transform(data[['sentiment_polarity', 'sentiment_subjectivity']])\n",
    "#vectorizing our strings of text\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(data['processed_text'])\n",
    "#stacking the text and sentiment \n",
    "X_combined = sp.hstack([X_vectorized, X_sentiment], format='csr')\n",
    "#target variable declaration\n",
    "y = data['political_leaning']\n",
    "#splitting data test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7105fbbd-fa5b-4bc3-9166-4e0eb341212b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a39229f7-a4b9-4e8d-a86f-1005dc457939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  Coefficient\n",
      "105301       fucking    -2.162276\n",
      "142683          isnt    -2.153745\n",
      "91942            etc     1.983148\n",
      "71709   deliberately    -1.979859\n",
      "304852         whole    -1.975374\n",
      "76648       disagree     1.861804\n",
      "49117       campaign    -1.848820\n",
      "200992      orthodox    -1.847472\n",
      "284922           two    -1.838165\n",
      "36113         beeing    -1.816784\n"
     ]
    }
   ],
   "source": [
    "#getting the names of the features\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "#seeing the coefficients in the model\n",
    "svm_coefs = clf.coef_.toarray()\n",
    "#creating a dataframe for every word and its coefficient \n",
    "coefs_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': svm_coefs[0]})\n",
    "\n",
    "# Sort by absolute values of coefficients to find most influential words\n",
    "most_important_words = coefs_df.reindex(coefs_df.Coefficient.abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(most_important_words.head(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f0c935-6abe-4bc3-9f2d-8583f2cdc86a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       0.60      0.80      0.68       974\n",
      "        left       0.74      0.45      0.56       609\n",
      "       right       0.64      0.57      0.60       707\n",
      "\n",
      "    accuracy                           0.63      2290\n",
      "   macro avg       0.66      0.60      0.62      2290\n",
      "weighted avg       0.65      0.63      0.63      2290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f4c441-5f40-4155-a961-9054f0d48642",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      center       0.58      0.81      0.68       974\n",
      "        left       0.73      0.39      0.51       609\n",
      "       right       0.64      0.55      0.59       707\n",
      "\n",
      "    accuracy                           0.62      2290\n",
      "   macro avg       0.65      0.58      0.59      2290\n",
      "weighted avg       0.64      0.62      0.61      2290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#here we also train the model for logistic regression (to compare)\n",
    "logistic = LogisticRegression(max_iter=1000)  \n",
    "logistic.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logistic.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
